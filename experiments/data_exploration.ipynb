{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import chi2_contingency\n",
    "import configparser\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def init_config():\n",
    "#     config = configparser.ConfigParser()\n",
    "#     config.read(\"../config.ini\")\n",
    "#     return config\n",
    "\n",
    "# def download_blob(config):\n",
    "#     \"\"\"Downloads a blob from the bucket.\"\"\"\n",
    "    \n",
    "#     # Initialize a storage client\n",
    "#     path = config['gcp']['cloud_storage']\n",
    "#     df = pd.read_csv(path)\n",
    "#     return df\n",
    "\n",
    "# config = init_config()\n",
    "# df = download_blob(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/kaitlin.brabec/OneDrive - PA Consulting Group/computer_recovery/downloads/HR_Analytics.csv.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "for column in categorical_columns:\n",
    "    df[column] = df[column].str.replace(' ', '_').str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no null\n",
    "df.isna().any().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store unique values for each int64 column in a dictionary\n",
    "# unique_values_dict = {}\n",
    "\n",
    "# for column in df.select_dtypes(include=['int64']).columns:\n",
    "#     unique_values_dict[column] = df[column].unique()\n",
    "\n",
    "# # Display the dictionary\n",
    "# unique_values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# X = df.drop(columns=['Attrition', \"BusinessTravel\",\"OverTime\", \"Gender\", \"MaritalStatus\", \"Department\", \"EducationField\",\"JobRole\" ])\n",
    "# y = df['Attrition']\n",
    "\n",
    "# # Standardize the features\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # Apply PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# principal_components = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "# pca_df['Attrition'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the principal components\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# sns.scatterplot(x='PC1', y='PC2', hue='Attrition', data=pca_df, palette='Set1', s=100)\n",
    "# plt.title('PCA of Features Colored by Attrition')\n",
    "# plt.xlabel('Principal Component 1')\n",
    "# plt.ylabel('Principal Component 2')\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Explained variance\n",
    "# explained_variance = pca.explained_variance_ratio_\n",
    "# explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # PCA components\n",
    "# components_df = pd.DataFrame(pca.components_, columns=X.columns, index=['PC1', 'PC2'])\n",
    "# components_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# X = df.drop(columns=['Attrition', \"BusinessTravel\",\"OverTime\", \"Gender\", \"MaritalStatus\", \"Department\", \"EducationField\",\"JobRole\" ])\n",
    "# y = df['Attrition']\n",
    "\n",
    "# # Train a RandomForestClassifier\n",
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# clf.fit(X, y)\n",
    "\n",
    "# # Get feature importances\n",
    "# feature_importances = pd.Series(clf.feature_importances_, index=X.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an imbalanced problem as there are 1233 No's and 237 Yes in Attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes(include=['int64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38&lt;=x&lt;45</td>\n",
       "      <td>yes</td>\n",
       "      <td>travel_rarely</td>\n",
       "      <td>942&lt;=x&lt;1224</td>\n",
       "      <td>sales</td>\n",
       "      <td>1&lt;=x&lt;2</td>\n",
       "      <td>2</td>\n",
       "      <td>life_sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1&lt;=x&lt;402</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8&lt;=x&lt;10</td>\n",
       "      <td>0&lt;=x&lt;2</td>\n",
       "      <td>1</td>\n",
       "      <td>5&lt;=x&lt;7</td>\n",
       "      <td>4&lt;=x&lt;7</td>\n",
       "      <td>0&lt;=x&lt;1</td>\n",
       "      <td>4&lt;=x&lt;7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45&lt;=x&lt;61</td>\n",
       "      <td>no</td>\n",
       "      <td>travel_frequently</td>\n",
       "      <td>102&lt;=x&lt;391</td>\n",
       "      <td>research_&amp;_development</td>\n",
       "      <td>5&lt;=x&lt;9</td>\n",
       "      <td>1</td>\n",
       "      <td>life_sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1&lt;=x&lt;402</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10&lt;=x&lt;17</td>\n",
       "      <td>3&lt;=x&lt;4</td>\n",
       "      <td>3</td>\n",
       "      <td>10&lt;=x&lt;41</td>\n",
       "      <td>7&lt;=x&lt;19</td>\n",
       "      <td>1&lt;=x&lt;4</td>\n",
       "      <td>7&lt;=x&lt;18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34&lt;=x&lt;38</td>\n",
       "      <td>yes</td>\n",
       "      <td>travel_rarely</td>\n",
       "      <td>1224&lt;=x&lt;1500</td>\n",
       "      <td>research_&amp;_development</td>\n",
       "      <td>2&lt;=x&lt;5</td>\n",
       "      <td>2</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>1&lt;=x&lt;402</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>5&lt;=x&lt;8</td>\n",
       "      <td>3&lt;=x&lt;4</td>\n",
       "      <td>3</td>\n",
       "      <td>0&lt;=x&lt;2</td>\n",
       "      <td>0&lt;=x&lt;1</td>\n",
       "      <td>0&lt;=x&lt;1</td>\n",
       "      <td>0&lt;=x&lt;1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29&lt;=x&lt;34</td>\n",
       "      <td>no</td>\n",
       "      <td>travel_frequently</td>\n",
       "      <td>1224&lt;=x&lt;1500</td>\n",
       "      <td>research_&amp;_development</td>\n",
       "      <td>2&lt;=x&lt;5</td>\n",
       "      <td>4</td>\n",
       "      <td>life_sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1&lt;=x&lt;402</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8&lt;=x&lt;10</td>\n",
       "      <td>3&lt;=x&lt;4</td>\n",
       "      <td>3</td>\n",
       "      <td>7&lt;=x&lt;10</td>\n",
       "      <td>7&lt;=x&lt;19</td>\n",
       "      <td>1&lt;=x&lt;4</td>\n",
       "      <td>0&lt;=x&lt;1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18&lt;=x&lt;29</td>\n",
       "      <td>no</td>\n",
       "      <td>travel_rarely</td>\n",
       "      <td>391&lt;=x&lt;656</td>\n",
       "      <td>research_&amp;_development</td>\n",
       "      <td>2&lt;=x&lt;5</td>\n",
       "      <td>1</td>\n",
       "      <td>medical</td>\n",
       "      <td>1</td>\n",
       "      <td>1&lt;=x&lt;402</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>5&lt;=x&lt;8</td>\n",
       "      <td>3&lt;=x&lt;4</td>\n",
       "      <td>3</td>\n",
       "      <td>2&lt;=x&lt;5</td>\n",
       "      <td>2&lt;=x&lt;4</td>\n",
       "      <td>1&lt;=x&lt;4</td>\n",
       "      <td>2&lt;=x&lt;4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age Attrition     BusinessTravel     DailyRate  \\\n",
       "0  38<=x<45       yes      travel_rarely   942<=x<1224   \n",
       "1  45<=x<61        no  travel_frequently    102<=x<391   \n",
       "2  34<=x<38       yes      travel_rarely  1224<=x<1500   \n",
       "3  29<=x<34        no  travel_frequently  1224<=x<1500   \n",
       "4  18<=x<29        no      travel_rarely    391<=x<656   \n",
       "\n",
       "               Department DistanceFromHome  Education EducationField  \\\n",
       "0                   sales           1<=x<2          2  life_sciences   \n",
       "1  research_&_development           5<=x<9          1  life_sciences   \n",
       "2  research_&_development           2<=x<5          2          other   \n",
       "3  research_&_development           2<=x<5          4  life_sciences   \n",
       "4  research_&_development           2<=x<5          1        medical   \n",
       "\n",
       "   EmployeeCount EmployeeNumber  ...  RelationshipSatisfaction StandardHours  \\\n",
       "0              1       1<=x<402  ...                         1            80   \n",
       "1              1       1<=x<402  ...                         4            80   \n",
       "2              1       1<=x<402  ...                         2            80   \n",
       "3              1       1<=x<402  ...                         3            80   \n",
       "4              1       1<=x<402  ...                         4            80   \n",
       "\n",
       "  StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  \\\n",
       "0                0            8<=x<10                 0<=x<2               1   \n",
       "1                1           10<=x<17                 3<=x<4               3   \n",
       "2                0             5<=x<8                 3<=x<4               3   \n",
       "3                0            8<=x<10                 3<=x<4               3   \n",
       "4                1             5<=x<8                 3<=x<4               3   \n",
       "\n",
       "   YearsAtCompany YearsInCurrentRole YearsSinceLastPromotion  \\\n",
       "0          5<=x<7             4<=x<7                  0<=x<1   \n",
       "1        10<=x<41            7<=x<19                  1<=x<4   \n",
       "2          0<=x<2             0<=x<1                  0<=x<1   \n",
       "3         7<=x<10            7<=x<19                  1<=x<4   \n",
       "4          2<=x<5             2<=x<4                  1<=x<4   \n",
       "\n",
       "  YearsWithCurrManager  \n",
       "0               4<=x<7  \n",
       "1              7<=x<18  \n",
       "2               0<=x<1  \n",
       "3               0<=x<1  \n",
       "4               2<=x<4  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_and_replace_bins(df, columns, num_bins=5):\n",
    "    binned_df = df.copy()\n",
    "    for col in columns:\n",
    "        col_range = df[col].max() - df[col].min()\n",
    "        if col_range > 5:\n",
    "            # Calculate quantile-based bins\n",
    "            _, bins = pd.qcut(df[col], q=num_bins, duplicates='drop', retbins=True)\n",
    "            # Adjust bins to integer values\n",
    "            bins = np.floor(bins).astype(int)\n",
    "            bins[-1] = bins[-1] + 1  # Ensure the last bin is inclusive\n",
    "            # Create labels based on bin edges\n",
    "            labels = [f'{bins[i]}<=x<{bins[i+1]}' for i in range(len(bins)-1)]\n",
    "            # Apply binning and replace original column\n",
    "            binned_df[col] = pd.cut(df[col], bins=bins, labels=labels, right=False, include_lowest=True)\n",
    "    return binned_df\n",
    "\n",
    "# Apply dynamic binning and replace columns\n",
    "binned_df_dynamic = create_and_replace_bins(df, numerical_columns, num_bins=5)\n",
    "\n",
    "# Display the first few rows of the modified dataframe\n",
    "binned_df_dynamic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': {'29<=x<34': 316,\n",
       "  '45<=x<61': 314,\n",
       "  '38<=x<45': 308,\n",
       "  '34<=x<38': 274,\n",
       "  '18<=x<29': 258},\n",
       " 'DailyRate': {'391<=x<656': 296,\n",
       "  '1224<=x<1500': 296,\n",
       "  '942<=x<1224': 294,\n",
       "  '102<=x<391': 292,\n",
       "  '656<=x<942': 292},\n",
       " 'DistanceFromHome': {'2<=x<5': 359,\n",
       "  '9<=x<17': 318,\n",
       "  '17<=x<30': 297,\n",
       "  '5<=x<9': 288,\n",
       "  '1<=x<2': 208},\n",
       " 'Education': {3: 572, 4: 398, 2: 282, 1: 170, 5: 48},\n",
       " 'EmployeeCount': {1: 1470},\n",
       " 'EmployeeNumber': {'1654<=x<2069': 295,\n",
       "  '1<=x<402': 294,\n",
       "  '402<=x<814': 294,\n",
       "  '1235<=x<1654': 294,\n",
       "  '814<=x<1235': 293},\n",
       " 'EnvironmentSatisfaction': {3: 453, 4: 446, 2: 287, 1: 284},\n",
       " 'HourlyRate': {'73<=x<87': 310,\n",
       "  '45<=x<59': 301,\n",
       "  '87<=x<101': 300,\n",
       "  '30<=x<45': 282,\n",
       "  '59<=x<73': 277},\n",
       " 'JobInvolvement': {3: 868, 2: 375, 4: 144, 1: 83},\n",
       " 'JobLevel': {1: 543, 2: 534, 3: 218, 4: 106, 5: 69},\n",
       " 'JobSatisfaction': {4: 459, 3: 442, 1: 289, 2: 280},\n",
       " 'MonthlyIncome': {'2695<=x<4228': 295,\n",
       "  '5743<=x<9860': 295,\n",
       "  '9860<=x<20000': 294,\n",
       "  '1009<=x<2695': 293,\n",
       "  '4228<=x<5743': 293},\n",
       " 'MonthlyRate': {'2094<=x<6887': 294,\n",
       "  '6887<=x<11773': 294,\n",
       "  '11773<=x<16714': 294,\n",
       "  '16714<=x<21712': 294,\n",
       "  '21712<=x<27000': 294},\n",
       " 'NumCompaniesWorked': {'1<=x<3': 667,\n",
       "  '5<=x<10': 308,\n",
       "  '3<=x<5': 298,\n",
       "  '0<=x<1': 197},\n",
       " 'PercentSalaryHike': {'13<=x<15': 410,\n",
       "  '15<=x<19': 350,\n",
       "  '19<=x<26': 302,\n",
       "  '11<=x<12': 210,\n",
       "  '12<=x<13': 198},\n",
       " 'PerformanceRating': {3: 1244, 4: 226},\n",
       " 'RelationshipSatisfaction': {3: 459, 4: 432, 2: 303, 1: 276},\n",
       " 'StandardHours': {80: 1470},\n",
       " 'StockOptionLevel': {0: 631, 1: 596, 2: 158, 3: 85},\n",
       " 'TotalWorkingYears': {'10<=x<17': 430,\n",
       "  '17<=x<41': 319,\n",
       "  '5<=x<8': 294,\n",
       "  '0<=x<5': 228,\n",
       "  '8<=x<10': 199},\n",
       " 'TrainingTimesLastYear': {'2<=x<3': 547,\n",
       "  '3<=x<4': 491,\n",
       "  '4<=x<7': 307,\n",
       "  '0<=x<2': 125},\n",
       " 'WorkLifeBalance': {3: 893, 2: 344, 4: 153, 1: 80},\n",
       " 'YearsAtCompany': {'10<=x<41': 366,\n",
       "  '2<=x<5': 365,\n",
       "  '5<=x<7': 272,\n",
       "  '7<=x<10': 252,\n",
       "  '0<=x<2': 215},\n",
       " 'YearsInCurrentRole': {'2<=x<4': 507,\n",
       "  '7<=x<19': 485,\n",
       "  '0<=x<1': 244,\n",
       "  '4<=x<7': 177,\n",
       "  '1<=x<2': 57},\n",
       " 'YearsSinceLastPromotion': {'0<=x<1': 581, '1<=x<4': 568, '4<=x<16': 321},\n",
       " 'YearsWithCurrManager': {'7<=x<18': 487,\n",
       "  '2<=x<4': 486,\n",
       "  '0<=x<1': 263,\n",
       "  '4<=x<7': 158,\n",
       "  '1<=x<2': 76}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_binned_value_counts(df, columns):\n",
    "    value_counts_dict = {}\n",
    "    for col in columns:\n",
    "        value_counts_dict[col] = df[col].value_counts().to_dict()\n",
    "    return value_counts_dict\n",
    "\n",
    "# Get value counts for each binned column\n",
    "get_binned_value_counts(binned_df_dynamic, numerical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Attrition'] = df['Attrition'].map(lambda x : 0 if x == 'no' else 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"BusinessTravel\"].unique()\n",
    "df[\"JobRole\"].unique()\n",
    "df[\"EducationField\"].unique()\n",
    "df[\"Department\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I would get rid of Marital Status and Gender -- whether or not keeping these featurs is based on the context \n",
    "#In this case you want to ensure that decisions are not influenced by gender or marital status, hence promoting fairness and ethics \n",
    "# you need to check potential correlation with other features and the target variable\n",
    "\n",
    "# Encoding categorical variables\n",
    "df['Gender'] = df['Gender'].map({'male': 1, 'female': 0})\n",
    "df['MaritalStatus'] = df['MaritalStatus'].map({'single': 0, 'married': 1, 'divorced': 2})\n",
    "\n",
    "# Contingency tables\n",
    "contingency_table_gender = pd.crosstab(df['Gender'], df['Attrition'])\n",
    "contingency_table_marital = pd.crosstab(df['MaritalStatus'], df['Attrition'])\n",
    "\n",
    "print(\"Contingency Table - Gender vs Target:\")\n",
    "print(contingency_table_gender)\n",
    "\n",
    "print(\"\\nContingency Table - Marital Status vs Target:\")\n",
    "print(contingency_table_marital)\n",
    "\n",
    "# Chi-Square tests\n",
    "chi2_gender, p_gender, dof_gender, ex_gender = chi2_contingency(contingency_table_gender)\n",
    "chi2_marital, p_marital, dof_marital, ex_marital = chi2_contingency(contingency_table_marital)\n",
    "\n",
    "print(f\"\\nChi-Square Test between gender and target: chi2 = {chi2_gender}, p-value = {p_gender}\")\n",
    "print(f\"Chi-Square Test between marital_status and target: chi2 = {chi2_marital}, p-value = {p_marital}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "print(\"\\nInterpretation:\")\n",
    "if p_gender < alpha:\n",
    "    print(\"There is a significant association between gender and target (p < 0.05).\")\n",
    "else:\n",
    "    print(\"There is no significant association between gender and target (p >= 0.05).\")\n",
    "\n",
    "if p_marital < alpha:\n",
    "    print(\"There is a significant association between marital status and target (p < 0.05).\")\n",
    "else:\n",
    "    print(\"There is no significant association between marital status and target (p >= 0.05).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Gender'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['StandardHours', 'Over18', 'EmployeeCount'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.MonthlyIncome.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_values_mi = df.sort_values(by='MonthlyIncome').reset_index(drop=True)\n",
    "bins_mi = ['x<2696', '2695<x<4230', '4229<x<5744', '5743<x<9884', '9883<x<19999']\n",
    "idxs_mi = [int(sorted_values_mi.iloc[(294*i)].MonthlyIncome) if 294*i < len(sorted_values_mi) else int(sorted_values_mi.iloc[len(sorted_values_mi)-1].MonthlyIncome) for i in range(1,6)]\n",
    "intervals_mi = list(zip(bins_mi,idxs_mi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_intervals(value):\n",
    "    for x in intervals_mi:\n",
    "        if value <= x[1]:\n",
    "            return x[0]\n",
    "    return value  # return original value if it doesn't match any interval\n",
    "\n",
    "df['MonthlyIncome'] = df['MonthlyIncome'].apply(match_intervals)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MonthlyIncome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.MonthlyRate.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_values_mr = df.sort_values(by='MonthlyRate').reset_index(drop=True)\n",
    "bins_mr = ['x<6889', '6888<x<11781', '11780<x<16734', '16733<x<21728', '21727<x<26999']\n",
    "idxs_mr = [int(sorted_values_mr.iloc[(294*i)].MonthlyRate) if 294*i < len(sorted_values_mr) else int(sorted_values_mr.iloc[len(sorted_values_mr)-1].MonthlyRate) for i in range(1,6)]\n",
    "intervals_mr = list(zip(bins_mr,idxs_mr))\n",
    "# idxs_mr\n",
    "# sorted_values_mr.iloc[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_intervals(value):\n",
    "    for x in intervals_mr:\n",
    "        if value <= x[1]:\n",
    "            return x[0]\n",
    "    return value  # return original value if it doesn't match any interval\n",
    "\n",
    "df['MonthlyRate'] = df['MonthlyRate'].apply(match_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MonthlyRate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram\n",
    "ax = df.NumCompaniesWorked.plot.hist()\n",
    "\n",
    "# Add labels\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(int(p.get_height())), (p.get_x() * 1.005, p.get_height() * 1.005))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values\n",
    "sorted_values_ncw = df.sort_values(by='NumCompaniesWorked').reset_index(drop=True)\n",
    "\n",
    "# Calculate the indices for each bin edge\n",
    "num_bins = 6\n",
    "idxs_ncw = [int(sorted_values_ncw.iloc[(len(sorted_values_ncw) // num_bins) * i].NumCompaniesWorked) for i in range(1, num_bins)]\n",
    "\n",
    "# Ensure no duplicate indices\n",
    "idxs_ncw = sorted(list(set(idxs_ncw)))\n",
    "\n",
    "# Add min and max values to the bin edges\n",
    "bin_edges_values = [sorted_values_ncw['NumCompaniesWorked'].min()] + idxs_ncw + [sorted_values_ncw['NumCompaniesWorked'].max()]\n",
    "\n",
    "# Create bins labels (you can customize these labels)\n",
    "bins_ncw = [f'x<{bin_edges_values[1]}'] + [f'{bin_edges_values[i]}<x<{bin_edges_values[i+1]}' for i in range(1, len(bin_edges_values)-2)] + [f'x>{bin_edges_values[-2]}']\n",
    "\n",
    "# Zip bin labels with bin edges for intervals\n",
    "intervals_ncw = list(zip(bins_ncw, bin_edges_values[1:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to match intervals\n",
    "def match_intervals(value):\n",
    "    for x in intervals_ncw:\n",
    "        if value <= x[1]:\n",
    "            return x[0]\n",
    "    return value  # return original value if it doesn't match any interval\n",
    "\n",
    "# Apply the function to the 'NumCompaniesWorked' column\n",
    "df['NumCompaniesWorked'] = df['NumCompaniesWorked'].apply(match_intervals)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df['NumCompaniesWorked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.PercentSalaryHike.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_values_psh = df.sort_values(by='PercentSalaryHike').reset_index(drop=True)\n",
    "bins_psh = ['x<12', '11<x<13', '12<x<15', '14<x<19', '18<x<25']\n",
    "idxs_psh = [int(sorted_values_psh.iloc[(294-1)*i].PercentSalaryHike) for i in range(1,6)]\n",
    "intervals_psh = list(zip(bins_psh,idxs_psh))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_intervals(value):\n",
    "    for x in intervals_psh:\n",
    "        if value <= x[1]:\n",
    "            return x[0]\n",
    "    return value  # return original value if it doesn't match any interval\n",
    "\n",
    "df['PercentSalaryHike'] = df['PercentSalaryHike'].apply(match_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PercentSalaryHike'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TotalWorkingYears.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_values_twy = df.sort_values(by='TotalWorkingYears').reset_index(drop=True)\n",
    "bins_twy = ['x<5', '4<x<8', '7<x<10', '9<x<17', '16<x<40']\n",
    "idxs_twy = [int(sorted_values_twy.iloc[(294*i)].TotalWorkingYears) if 294*i < len(sorted_values_twy) else int(sorted_values_twy.iloc[len(sorted_values_twy)-1].TotalWorkingYears) for i in range(1,6)]\n",
    "intervals_twy = list(zip(bins_twy,idxs_twy))\n",
    "intervals_twy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_intervals(value):\n",
    "    for x in intervals_twy:\n",
    "        if value <= x[1]:\n",
    "            return x[0]\n",
    "    return value  # return original value if it doesn't match any interval\n",
    "\n",
    "df['TotalWorkingYears'] = df['TotalWorkingYears'].apply(match_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalWorkingYears'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram\n",
    "ax = df.YearsAtCompany.plot.hist()\n",
    "\n",
    "# Add labels\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(int(p.get_height())), (p.get_x() * 1.005, p.get_height() * 1.005))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age \n",
    "df.Age.plot.hist()\n",
    "# based on the distribution let's split into 5 bins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_values = df.sort_values(by='Age').reset_index(drop=True)\n",
    "bins = ['x<30', '29<x<35', '34<x<39', '44<x<46', '44<x<61']\n",
    "idxs = [int(sorted_values.iloc[(294-1)*i].Age) for i in range(1,6)]\n",
    "intervals = list(zip(bins,idxs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_intervals(value):\n",
    "    for x in intervals:\n",
    "        if value <= x[1]:\n",
    "            return x[0]\n",
    "    return value  # return original value if it doesn't match any interval\n",
    "\n",
    "df['Age'] = df['Age'].apply(match_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.DailyRate.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_values_dr = df.sort_values(by='DailyRate').reset_index(drop=True)\n",
    "idxs_dr = [int(sorted_values_dr.iloc[(245*i)].DailyRate) if 245*i < len(sorted_values_dr) else int(sorted_values_dr.iloc[len(sorted_values_dr)-1].DailyRate) for i in range(1,7)]\n",
    "bins_dr = ['x<335', '334<x<573', '572<x<802', '801<x<1040','1039<x<1274', '1273<x<1499']\n",
    "\n",
    "\n",
    "intervals_dr = list(zip(bins_dr,idxs_dr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_intervals(value):\n",
    "    for x in intervals_dr:\n",
    "        if value <= x[1]:\n",
    "            return x[0]\n",
    "    return value  # return original value if it doesn't match any interval\n",
    "\n",
    "df['DailyRate'] = df['DailyRate'].apply(match_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DailyRate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.DistanceFromHome.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_values_dfh = df.sort_values(by='DistanceFromHome').reset_index(drop=True)\n",
    "idxs_dfh = [int(sorted_values_dfh.iloc[(294-1)*i].DistanceFromHome) for i in range(1,6)]\n",
    "bins_dfh = ['x<2', '1<x<5', '4<x<9', '8<x<16','15<x<29']\n",
    "\n",
    "intervals_dfh = list(zip(bins_dfh,idxs_dfh))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_values_mi = df.sort_values(by='MonthlyIncome').reset_index(drop=True)\n",
    "bins_mi = ['x<2561', '2560<x<3633', '3632<x<4930', '4929<x<6538', '6537<x<19999']\n",
    "idxs_mi = [int(sorted_values_mi.iloc[(294*i)].MonthlyIncome) if 294*i < len(sorted_values_mi) else int(sorted_values_mi.iloc[len(sorted_values_mi)-1].MonthlyIncome) for i in range(1,6)]\n",
    "\n",
    "intervals_mi = list(zip(bins_mi,idxs_mi))\n",
    "intervals_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def match_intervals(value):\n",
    "    for x in intervals_mi:\n",
    "        if value <= x[1]:\n",
    "            return x[0]\n",
    "    return value  # return original value if it doesn't match any interval\n",
    "\n",
    "df['MonthlyIncome'] = df['MonthlyIncome'].apply(match_intervals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MonthlyIncome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_intervals(value):\n",
    "    for x in intervals_dfh:\n",
    "        if value <= x[1]:\n",
    "            return x[0]\n",
    "    return value  # return original value if it doesn't match any interval\n",
    "\n",
    "df['DistanceFromHome'] = df['DistanceFromHome'].apply(match_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DistanceFromHome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.HourlyRate.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_values_hr = df.sort_values(by='HourlyRate').reset_index(drop=True)\n",
    "bins_hr = ['x<29', '28<x<34', '33<x<38', '37<x<45', '44<x<61']\n",
    "idxs_hr = [int(sorted_values_hr.iloc[(294-1)*i].HourlyRate) for i in range(1,6)]\n",
    "intervals_hr = list(zip(bins_hr,idxs_hr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_intervals(value):\n",
    "    for x in intervals_hr:\n",
    "        if value <= x[1]:\n",
    "            return x[0]\n",
    "    return value  # return original value if it doesn't match any interval\n",
    "\n",
    "df['HourlyRate'] = df['HourlyRate'].apply(match_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HourlyRate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HourlyRate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_values_mi = df.sort_values(by='MonthlyIncome').reset_index(drop=True)\n",
    "bins_mi = ['x<2561', '2560<x<3633', '3632<x<4930', '4929<x<6538', '6537<x<19999']\n",
    "idxs_mi = [int(sorted_values_mi.iloc[(294*i)].MonthlyIncome) if 294*i < len(sorted_values_mi) else int(sorted_values_mi.iloc[len(sorted_values_mi)-1].MonthlyIncome) for i in range(1,6)]\n",
    "\n",
    "intervals_mi = list(zip(bins_mi,idxs_mi))\n",
    "intervals_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_intervals(value):\n",
    "    for x in intervals_mi:\n",
    "        if value <= x[1]:\n",
    "            return x[0]\n",
    "    return value  # return original value if it doesn't match any interval\n",
    "\n",
    "df['MonthlyIncome'] = df['MonthlyIncome'].apply(match_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MonthlyIncome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business Travel\n",
    "\n",
    "df['BusinessTravel'].value_counts()\n",
    "# in this case we will use label encoding -- you should check the reason !! we could have choosen one-hot but we didn't ...\n",
    "df['BusinessTravel'] = df['BusinessTravel'].apply(lambda x: 0 if x =='Non-Travel' else (1 if x == 'Travel_Rarely' else 2))\n",
    "\n",
    "# Department\n",
    "\n",
    "df['Department'].value_counts()\n",
    "department_dummies = pd.get_dummies(df['Department'], prefix='Department', dtype=float) # why now we used one-hot encoding and not label encoding?\n",
    "df.drop(columns=['Department'], inplace=True)\n",
    "df = pd.concat([df,department_dummies], axis=1)\n",
    "\n",
    "# Education Field and JobRole\n",
    "\n",
    "for field in ['JobRole', 'EducationField', 'Age']:\n",
    "\n",
    "    df[field].value_counts()\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    new_data = lb.fit_transform(df[field])\n",
    "    binary_df = pd.DataFrame(new_data, columns=lb.classes_)\n",
    "    df.drop(columns=[field], inplace=True)\n",
    "    pd.concat([df,binary_df], axis=1)\n",
    "\n",
    "\n",
    "# OverTime\n",
    "\n",
    "df['OverTime'] = df['OverTime'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update pre-processed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_URI = \"gs://pipeline_hr_analytics/\"\n",
    "FOLDER = \"pre_processed_data/\"\n",
    "\n",
    "path = \"\".join([BUCKET_URI, FOLDER])\n",
    "\n",
    "df.to_csv(path + 'pre_processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "auto-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will show you how to set up automl \n",
    "\n",
    "# First create a dataset \n",
    "\n",
    "import os\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "PROJECT_ID = \"prj-dev-mlcc-flt-01-bbc1\"\n",
    "REGION = \"us-west4\"\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "dataset = aiplatform.TabularDataset.create(\n",
    "    display_name=\"HR Analytics\",\n",
    "    gcs_source=f\"{path}pre_processed_data.csv\",\n",
    ")\n",
    "\n",
    "label_column = \"Attrition\"\n",
    "\n",
    "print(dataset.resource_name)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = aiplatform.AutoMLTabularTrainingJob(\n",
    "  display_name=\"train-automl-hr-analytics\",\n",
    "  optimization_prediction_type=\"classification\",\n",
    "  optimization_objective=\"maximize-au-prc\",\n",
    ")\n",
    "\n",
    "model = job.run(\n",
    "    dataset=dataset,\n",
    "    target_column=label_column,\n",
    "    training_fraction_split=0.6,\n",
    "    validation_fraction_split=0.2,\n",
    "    test_fraction_split=0.2,\n",
    "    budget_milli_node_hours=1000,\n",
    "    model_display_name=\"test\",\n",
    "    disable_early_stopping=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
